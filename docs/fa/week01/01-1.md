---
lang-ref: ch.01-1
lecturer: Yann LeCun
title: انگیزه‌ی پشت یادگیری عمیق، ایده و تاریخچه‌ی آن
authors: Yunya Wang, SunJoo Park, Mark Estudillo, Justin Mae
date: 27 Jan 2020
lang: fa
translation-date: 15 July 2022
translator: Nima Afshar
---

<!--
## [Course plan](https://www.youtube.com/watch?v=0bMe_vCZo30&t=217s)

- Basics of Supervised Learning, Neural Nets, Deep Learning
- Backpropagation and architectural components
- Convolutional neural network and its applications
- More Deep Learning Architectures
- Regularization Tricks / Optimization Tricks / Understanding how Deep Learning works
- Energy-based models
- Self-supervised learning and beyond
-->


## [برنامه‌ی درس](https://www.youtube.com/watch?v=0bMe_vCZo30&t=217s)

- مبانی یادگیری با نظارت
*(supervised)*،
شبکه‌های عصبی و یادگیری عمیق
- پس‌انتشار 
*(Backpropagation)*
و اجزای معماری شبکه‌های عصبی
- شبکه‌های عصبی کانولوشنی و کاربرد آنها
- دیگر معماری‌های شبکه‌های عصبی
- روش‌های *Regularization* / روش‌های بهینه‌سازی / فهم اینکه یادگیری عمیق چگونه کار می‌کند
- مدل‌های بر پایه‌ی انرژی
- یادگیری خودناظر
*(Self-supervised)* و فراتر از آن


<!--
## Inspiration of Deep Learning and its history
-->


## ایده‌ی یادگیری عمیق و تاریخچه‌ی آن


<!--
On a conceptual level, deep learning is inspired by the brain but not all of the brain's details are relevant. For a comparison, aeroplanes were inspired by birds. The principle of flying is the same but the details are extremely different.
-->


به صورت کلی و مفهومی، یادگیری عمیق از مغز انسان الهام گرفته شده است. ولی تمامی جزئیات مغز در آن کپی نشده زیرا کاربردی نیستند. مثل هواپیماها که از پرندگان الهام گرفته شده‌اند. اصول کلی پرواز در آنها یکسان است ولی جزئیات بسیار متفاوت است.


<!--
The history of deep learning goes back to a field which changed its name now to cybernetics. It started in the 1940s with McCulloch and Pitts. They came up with the idea that neurons are threshold units with on and off states. You could build a Boolean circuit by connecting neurons with each other and conduct logical inference with neurons. The brain is basically a logical inference machine because neurons are binary. Neurons compute a weighted sum of inputs and compare that sum to its threshold. It turns on if it's above the threshold and turns off if it's below, which is a simplified view of how neural networks work.
-->

تاریخچه‌ی یادگیری عمیق به حوزه‌ای از علم برمی‌گردد که امروز سایبرنتیک
*(cybernetics)*
خوانده می‌شود. این حوزه در دهه‌ی ۱۹۴۰ میلادی با 
*McCulloch*
و
*Pitts*
شروع به کار کرد. آنها به این ایده رسیدند که نورون‌های مغز در واقع کلیدهایی دارای آستانه
*(threshold)*
هستند که بسته به آستانه‌شان بین دو حالت خاموش و روشن جابجا می‌شوند.
شما می‌توانید با اتصال تعدادی نورون یک مدار منطقی دودویی  بسازید و به این شکل با نورون‌ها استنتاج منطقی کنید.
پس مغز نسان در واقع یک ماشین استنتاج منطقی است زیرا نورون‌ها دودویی هستند (دارای دو حالت خاموش و روشن می‌باشند).
هر نورون یک جمع وزن‌دار 
*(weighted sum)*
از ورودی‌های خود را محاسبه می‌کند و آن را با آستانه‌ی خود مقایسه می‌کند. در صورتی که این جمع بالاتر از آستانه‌ی نورون باشد نورون روشن می‌شود و در غیر این صورت نورون خاموش می‌شود. اگر بخواهیم به صورت خیلی ساده‌سازی شده نگاه کنیم، شبکه‌های عصبی نیز به همین شکل کار می‌کنند.


<!--
In 1947, Donald Hebb had the idea that neurons in the brain learn by modifying the strength of the connections between neurons. This is called hyper learning, where if two neurons are fired together, then the connection linked between them increases; if they don't fire together, then the connection decreases.
-->


در ۱۹۴۷،
*Donald Hebb*
این ایده را مطرح کرد که نورون‌های مغز با تغییر دادن استحکام اتصالات خود با سایر نورون‌ها یاد می‌گیرند. به این شکل که اگر دو نورون با هم خروجی بدهند، اتصال میان آنها قوی خواهد و اگر با هم خروجی ارسال نکنند، اتصال میانشان ضعیف خواهد شد. به چنین روشی از یادگیری 
*hyper learning*
گفته می‌شود.


<!--
Later in 1948, cybernetics were proposed by Norbert Wiener, which is the idea that by having systems with sensors and actuators, you have a feedback loop and a self-regulatory system. The rules of the feedback mechanism of a car all come from this work.
-->


بعدا در ۱۹۴۸، ایده‌ی سایبرنتیک توسط
*Norbert Wiener*
پیشنهاد شد. این ایده به این معنی است که با داشتن سیستم‌هایی دارای محرک و سنسور، ما یک
*حلقه‌ی بازخورد
(feedback loop)*
و یک *سیستم خود-تنظیم
(self-regulatory)*
داریم. قوانین مربوط به سیستم بازخورد ماشین‌ها همه از این ایده نشئت گرفته‌اند.


<!--
In 1957, Frank Rosenblatt proposed the Perceptron, which is a learning algorithm that modifies the weights of very simple neural nets.
-->


در سال ۱۹۵۷،
*Frank Rosenblatt*
ایده‌ی پرسپترون
*(Perceptron)*
را مطرح کرد که یک الگوریتم یادگیری است که وزن‌های یک شبکه عصبی بسیار ساده را تنظیم می‌کند.



<!--
Overall, this idea of trying to build intellectual machines by simulating lots of neurons was born in 1940s, took off in 1950s, and completely died in late 1960s. The main reasons for the field dying off in 1960 are:
-->


در کل، ایده‌ی ساخت ماشین‌های خردمند با شبیه‌سازی تعداد زیادی نورون در دهه‌ی ۴۰ میلادی متولد شد، در دهه‌ی ۵۰ اوج گرفت و در اواخر دهه‌ی ۶۰ به طور کامل به فراموشی سپرده شد. از دلایل فراموش شدن این حوزه در اواخر دهه‌ی ۶۰ می‌توان به موارد زیر اشاره کرد:


<!--
- The researchers used neurons that were binary. However, the way to get backpropagation to work is to use activation functions that are continuous. At that time, researchers didn't have the idea of using continuous neurons and they didn't think they can train with gradients because binary neurons are not differential.
- With continuous neurons, one would have to multiply the activation of a neuron by a weight to get a contribution to the weighted sum. However, before 1980, the multiplication of two numbers, especially floating-point numbers, were extremely slow. This resulted in another incentive to avoid using continuous neurons.
-->
- محققان در آن زمان از نورون‌هایی که استفاده می کردند که حالت دودویی یا باینری داشتند. اما برای اینکه پس‌انشار کار کند نیاز به توابع فعالسازی‌ای 
*(activation function)*
داریم که پیوسته باشند. در آن زمان محققین ایده‌ای در مورد استفاده از نورون‌های پیوسته نداشتند و همینطور فکر نمی‌کردند که شبکه‌های خود را با استفاده از گرادیان آموزش دهند. چون نورون‌های دودویی مشتق‌پذیر نبودند.
- حتی برای استفاده از نورون‌های پیوسته، لازم است تا هر کدام از فعالساز‌های نورون در وزن خاصی ضرب شود تا مجموع وزن‌دار را بدست بیاوریم. اما قبل از دهه‌ی ۸۰ میلادی، ضرب دو عدد، به خصوص اعداد ممیز شناور
*(floating-point)*،
بسیار کند بود. این موضوع مشوق دیگری بود برای اینکه از نورون‌های پیوسته استفاده نشود.


<!--
Deep Learning took off again in 1985 with the emergence of backpropagation. In 1995, the field died again and the machine learning community abandoned the idea of neural nets. In early 2010, people start using neuron nets in speech recognition with huge performance improvement and later it became widely deployed in the commercial field. In 2013, computer vision started to switch to neuron nets. In 2016, the same transition occurred in natural language processing. Soon, similar revolutions will occur in robotics, control, and many other fields.
-->


یادگیری عمیق دوباره در سال ۱۹۸۵ با پدیدار شدن پس‌انتشار
*(backpropagation)*
اوج گرفت. در ۱۹۹۵، دوباره این حوزه به فراموشی سپرده شد و جامعه‌ی یادگیری ماشین ایده‌ی استفاده از شبکه‌های عصبی را کنار گذاشت. در اوایل دهه‌ی 
۲۰۱۰ میلادی،
مردم شروع به استفاده از شبکه‌های عصبی برای تشخیص صدا کردند. شبکه‌های عصبی در حوزه‌ی تشخیص صدا
*(speech recognition)*
باعث پیشرفت زیادی در دقت مدل‌ها شدند و این باعث شد که بعدتر به صورت گسترده در محصولات تجاری نیز مورد استفاده قرار گیرند. در سال ۲۰۱۳ افراد در حوزه‌ی بینایی ماشین نیز شروع به استفاده گسترده از شبکه‌های عصبی در مدل‌های خود کردند. در سال ۲۰۱۶ همین تغییر در حوزه‌ی پردازش زبان طبیغی نیز رخ داد. به زودی شبکه‌های عصبی انقلاب‌های مشابهی در حوزه‌های رباتیک، کنترل و ... نیز به وجود خواهند آورد.


<!--
### Supervised Learning
-->
### یادگیری با نظارت *(Supervised)*


<!--
$90\%$ of deep learning applications use supervised learning. Supervised learning is a process by which, you collect a bunch of pairs of inputs and outputs, and the inputs are feed into a machine to learn the correct output. When the output is correct, you don't do anything. If the output is wrong, you tweak the parameter of the machine and correct the output toward the one you want. The trick here is how you figure out which direction and how much you tweak the parameter and this goes back to gradient calculation and backpropagation.
-->


$90\%$ از کاربرد‌های یادگیری عمیق با استفاده از یادگیری با نظارت می‌باشد.
یادگیری با نظارت فرآیندی است که در آن تعدادی جفت ورودی-خروجی جمع آوری می‌کنیم. و ورودی‌ها را به یک ماشین می‌دهیم تا با استفاده از الگوریتمی خروجی درست مربوط به آنها را یاد بگیرد. به ازای یک ورودی اگر خروجی ماشین درست بود، کاری انجام نمی‌دهیم. ولی اگر خروجی ماشین غلط بود، پارامترهای ماشین را طوری تغییر می‌دهیم که خروجی ماشین به سمت خروجی درست نزدیک شود. چالش کار اینجاست که باید بفهمیم چقدر و به چه سمتی باید هریک از پارامتر‌های ماشین را تغییر دهیم تا اتفاق مورد نظر بیافتد. و این کار را با استفاده از محاسبه‌ی گرادیان و پس‌انتشار انجام می‌دهیم.


<!--
Supervised learning stems from Perceptron and Adaline. The Adaline is based on the same architecture with weighted inputs; when it is above the threshold, it turns on and below the threshold, it turns off. The Perceptron is a 2-layer neuron net where the second layer is trainable and the first layer is fixed. Most of the time, the first layer is determined randomly and that's what they call associative layers.
-->
یادگیری با نظارت از
*Perceptron*
و
*Adaline*
ریشه می‌گیرد.
*Adaline*
دارای معماری مشابهی است که در آن هرکدام از ورودی‌ها دارای یک وزن هستند. مجموع وزن‌دار ورودی‌ها محاسبه می‌شود و اگر این مجموع بالای آستانه
*(threshold)*
باشد، 
*Adaline*
روشن می‌شود و اگر پایین آستانه باشد،
*Adaline*
خاموش می‌شود.
*Perceptron*
یک نورون دو لایه است که لایه‌ی اول آن ثابت و لایه‌ی دوم آن قابل آموزش است.
بیشتر اوقات وزن‌های لایه‌ی اول به صورت تصادفی تغیین می‌شود. به همین دلیل به آنها لایه‌های شرکت‌پذیر گفته می‌شود.


<!--
## [History of Pattern Recognition and introduction to Gradient Descent](https://www.youtube.com/watch?v=0bMe_vCZo30&t=1461s)
-->
## [تاریخچه‌ی شناسایی الگو *(Pattern Recognition)* و معرفی الگوریتم گرادیان کاهشی](https://www.youtube.com/watch?v=0bMe_vCZo30&t=1461s)


<!--
The foregoing is the conceptual basis of pattern recognition before deep learning developed. The standard model of pattern recognition consists of feature extractor and trainable classifier. Input goes into the feature extractor, extracting relevant useful characteristics of inputs such as detecting an eye when the purpose is recognizing the face. Then, the vector of features is fed to the trainable classifier for computing weighted sum and comparing it with the threshold. Here, a trainable classifier could be a perceptron or single neural network. The problem is feature extractor should be engineered by hand. Which means, pattern recognition/computer vision focus on feature extractor considering how to design it for a particular problem, not much devoted to a trainable classifier.
-->


در ادامه به مفاهیم کلی شناسایی الگو قبل از توسعه یادگیری عمیق می‌پردازیم. مدل استاندارد شناسایی الگو از یک 
*feature extractor*
و یک 
*classifier*
تشکیل شده است که قسمت 
*classifier*
آن قابل آموزش دادن است.
ابتدا ورودی به 
*feature extractor*
داده می‌شود که مشخصه‌های مفید و مربوط به مسئله را از آن استخراج می‌کند.
مثلا وقتی که مسئله‌ی ما تشخیص چهره است یکی از مشخصه‌های مفید تشخیص چشم در تصویر است. در این مرحله
*feature extractor*
ویژگی‌های مفید را به صورت یک بردار عددی برمی‌گرداند.
سپس این بردار به یک 
*classifier*
داده می‌شود تا جمع وزن‌دار آنها را محاسبه کند و با آستانه‌ مقایسه کند.
این
*classifier*
قابل آموزش است یعنی پارامتر‌های آن می‌تواند با استفاده از داده‌ها یاد گرفته شود. این
*classifier*
می‌تواند یک 
*perceptron*
یا یک شبکه عصبی با یک نورون باشد.
مشکل اینجاست که 
*feature extractor*
باید به صورت دستی طراحی و مهندسی شود. پس شناسایی الگو یا بینایی ماشین بسیار بر روی نحوه‌ی طراحی
*feature extractor*
برای هر مسئله‌ی خاص متمرکز بوده است. و تمرکز کمی روی قسمت
*classifier*
بوده است.


<!--
After the emergence and development of deep learning, the 2-stage process changed to the sequences of modules. Each module has tunable parameters and nonlinearity. Then, stack them making multiple layers. This is why it is called “deep learning”. The reason why using nonlinearity rather than linearity is that two linear layers could be one linear layer since the composition of two linear is linear.
-->


بعد از پیدایش و توسعه‌ی یادگیری عمیق، این روند دو مرحله‌ای تبدیل به یک دنباله از ماژول‌های پشت سر هم شد. هر ماژول دارای پارامتر‌های قابل تنظیم و یک تابع غیر خطی است. پس قرار دادن چندتا از این ماژول‌ها پشت سر هم اصطلاحا چند لایه را ایجاد می‌کند. به همین دلیل به آن یادگیری 
"عمیق"
گفته می‌شود.
به این دلیل از یک تابع (تبدیل) غیر خطی در هر لایه استفاده می‌شود که اگر ۲ لایه‌ که صرفا دارای تبدیل خطی هستند را پشت هم قرار دهیم، معادل یک لایه با تبدیل خطی خواهند بود. به این خاطر که ترکیب دو تبدیل خطی یک تبدیل خطی است.
(می‌توان ترکیب (ضرب) دو ماتریس را با ی ماتریس دیگر نشان داد.)


<!--
The simplest multi-layer architecture with tunable parameters and nonlinearity could be: the input is represented as a vector such as an image or audio. This input is multiplied by the weight matrix whose coefficient is a tunable parameter. Then, every component of the result vector is passed through a nonlinear function such as ReLU. Repeating this process, it becomes a basic neural network. The reason why it is called a neural network is that this architecture calculates the weighted sum of components of input by corresponding rows of a matrix.
-->


ساده‌ترین معماری چندلایه با پارامتر‌های قابل تنظیم و تبدیل غیرخطی می‌تواند به این صورت باشد:
ورودی به صورت یک بردار نشان داده می‌شود که این بردار حاوی داده‌های یک عکس یا صدای ضبط شده است. این بردار در یک ماتریس ضرب می‌شود که تمام درایه‌های آن قابل تنظیم هستند. سپس تمامی درایه‌های بردار خروجی به یک تبدیل غیرخطی مثل
*ReLU* داده می‌شوند. با تکرار این روند، ما یک شبکه عصبی خواهیم داشت. دلیل اینکه به چنین مدلی شبکه عصبی گفته می‌شود این است که در این معماری مجموع وزن‌دار عناصر ورودی با ضرب آنها در ردیف‌های مربوطه در ماتریس محاسبه می‌شود.


<!--
Back to the point of supervised learning, we are comparing the resulting output with target output then optimize the objective function which is the loss, computing a distance/penalty/divergence between the result and target. Then, average this cost function over the training set. This is the goal we want to minimize. In other words, we want to find the value of the parameters that minimize this average.
-->
برای اینکه در شبکه‌های عصبی یادگیری با نظارت داشته باشیم، خروجی بدست آمده از شبکه را با خروجی مورد نظر مقایسه می‌کنیم. سپس سعی می‌کنیم تا تابع هدف که همان
*loss*
است را بهینه‌سازی کنیم.
این تابع یک فاصله/پنالتی/دایورژانس بین خروجی شبکه و خروجی درست محاسبه می‌کند. سپس این فاصله را برای همه‌ی موارد موجود در مجموعه
*train*
میانگین می‌گیرد.
و این میانگین متغیر هدف ما است که می‌خواهیم آن را مینیمم کنیم. به عبارت دیگر، می‌خواهیم مقداری از پارامتر‌ها را پیدا کنیم که این متغیر را مینیمم می‌کند.


<!--
The method of how to find it is computing gradient. For example, if we are lost in a smooth mountain at foggy night and want to go to the village in the valley. One way could be turning around and seeing which way the steepest way is to go down then take a small step down. The direction is (negative) gradient. With the assumption that the valley is convex, we could reach the valley.
-->
با محاسبه‌ی گرادیان می‌توانیم مقدار گفته شده برای پارامتر‌ها را پیدا کنیم. برای مثال اگر ما در یک کوهستان به نسبت هموار در یک شب پر از مه گم شده باشیم، و بخواهیم به سمت روستای داخل دره برویم، می‌توانیم در هر قدم اطراف خود را نگاه کنیم و در هر جهتی که بیشتر به سمت پایین می‌رود قدم برداریم. به این جهت (منفی) گرادیان می‌گویند. اگر فرض کنیم که دره‌ی ما 
*convex*
(محدب) است، به این شکل می‌توانیم به دره برسیم.


<!--
The more efficient way is called Stochastic Gradient Descent (SGD). Since we want to minimize average loss over the training set, we take one sample or small group of samples and calculate the error, then use gradient descent. Then, we take a new sample and get a new value for the error, then get the gradient which is a different direction normally. Two of the main reasons for using SGD are that it helps a model to converge fast empirically if the training set is very large and it enables better generalization, which means getting similar performance on various sets of data.
-->


روش کاراتر برای همین کار گرادیان کاهشی تصادفی 
*( Stochastic Gradient Descent)*
یا به طور خلاصه 
*SGD*
نام دارد. از آنجایی که ما می‌خواهیم هزینه
*(loss)*
متوسط را روی کل مجموعه‌ی
*train*
کاهش دهیم، یک نمونه یا تعداد کمی نمونه از این مجموعه برمیداریم و خطا یا همان تابع هزینه را روی آنها محاسبه می‌کنیم. سپس از گرادیان کاهشی استفاده می‌کنیم.
پس از آن دوباره یک نمونه میگیریم و برای آن به مقدار جدیدی از خطا می‌رسیم و از روی این خطای جدید گرادیان میگیریم که معمولا در جهت متفاوتی نسبت به نمونه‌ی قبلی است. دو تا از دلایل استفاده از 
*SGD*
این است که در صورتی که مجموعه‌ی
*train*
بسیار بزرگ باشد، به طور تجربی به مدل کمک می‌کند تا سریع‌تر 
*converge*
کند (به نتیجه برسد)
و به این موضوع که مدل
*generalization*
بالاتری داشته باشد نیز کمک می‌کند. به این معنی که مدل عملکرد مشابهی روی مجموعه داده‌های مختلف خواهد داشت.


### [محاسبه‌ی گرادیان با استفاده از پس‌انتشار *(backpropagation)*](https://www.youtube.com/watch?v=0bMe_vCZo30&t=2336s)


<!--
Computing gradients by backpropagation is a practical application of the chain rule. The backpropagation equation for the input gradients is as follows:
-->


محاسبه‌ی گرادیان با استفاده از پس‌انتشار یک کاربرد عملی از قاعده‌ی زنجیری
*(chain rule)*
است. معادله‌ی پس‌انتشار برای گرادیان‌های ورودی‌های لایه‌ها به صورت زیر است:


$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{x}_{i - 1}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial \boldsymbol{x}_i}{\partial \boldsymbol{x}_{i - 1}} \\
\frac{\partial C}{\partial \boldsymbol{x}_{i - 1}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial f_i(\boldsymbol{x}_{i - 1}, \boldsymbol{w}_i)}{\partial \boldsymbol{x}_{i - 1}}
\end{aligned}
$$

<!--
The backpropagation equation for the weight gradients is as follows:
-->


معادله‌ی پس‌انتشار برای گرادیان‌های پارامتر‌ها صورت زیر است:


$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{w}_{i}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial \boldsymbol{x}_i}{\partial \boldsymbol{w}_{i}} \\
\frac{\partial C}{\partial \boldsymbol{w}_{i}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial f_i(\boldsymbol{x}_{i - 1}, \boldsymbol{w}_i)}{\partial \boldsymbol{w}_{i}}
\end{aligned}
$$


<!--
Note that instead of scalar inputs, they will be vector inputs. More generally, multi-dimensional inputs. Backpropagation allows you to compute the derivative of the difference of the output you want and the output you get (which is the value of the objective function) with respect to any value inside the network. Finally, backpropagation is essential as it applies to multiple layers.
-->


دقت کنید ورودی‌های لایه‌های ما به جای اینکه مقادیر اسکالر
*(scalar)*
باشند، بردارد هستند. یا به صورت کلی‌تر، آرایه‌های چند بعدی هستند. پس انتشار اجازه می‌دهد تا مشتق تفاوت بین خروجی مدل و خروجی مطلوب (یا همان مقدار تابع هدف) را نسبت به هر متغیری داخل شبکه محاسبه کنیم. در نهایت می‌توان گفت که پس‌انتشار ضروری است زیرا می‌تواند به چندین لایه نیز اعمال شود و مشتق تابع هدف را نسبت به متغیرهای آنها محاسبه کند.


<!--
It is important to consider how to interpret inputs. For example, an image of 256$$\times$$256 would require a 200,000 valued matrix. These would be huge matrices that the neural network layers will need to handle. It would be impractical to utilize such matrices. Therefore, it is important to make hypothesis of the structure of the matrix.
-->

مهم است که چگونه ورودی را تفسیر می‌کنیم. برای مثال، یک عکس
$256 \times 256$
نیاز به یک ماتریس با 
۲۰۰۰۰۰
درایه دارد. و لایه‌های شبکه عصبی باید چنین ماتریسی را هندل کنند. ولی به کار بردن چنین ماتریس‌هایی غیرعملی خواهد بود. بنابرین بسیار مهم است که بنا بر ساختار داده‌ها (در اینجا ماتریس تصویر) فرض‌هایی بکنیم که مدل را ساده‌تر و کاراتر کند.


<!--
## Hierarchical representation of the Visual Cortex
-->


## ارائه شدن تصاویر به صورت سلسله‌مراتبی توسط قشر بینایی مغز


<!--
Experiments by Fukushima gave us an understanding of how our brain interprets the input to our eyes. In summary, it was discovered that neurons in front of our retina compress the input (known as contrast normalization) and the signal travels from our eyes to our brain. After this, the image gets processed in stages and certain neurons get activated for certain categories. Hence, the visual cortex does pattern recognition in a hierarchical manner.
-->


آزمایشات 
*Fukushima*
به فهم ما از این مسئله کمک کرد که چگونه مغز ما ورودی که از سمت چشمان ما به آن می‌رسد را تحلیل می‌کند. به طور خلاصه، کشف شد که نورون‌های جلوی شبکیه‌ی چشم ما ورودی را فشرده می‌کنند.
(به آن فرآیند *contrast normalization* گفته می‌شود.) 
و این سیگنال از چشم به مغز ما منتقل می‌شود. پس از آن این تصویر در مغز در چندین مرحله پردازش می‌شود و نورون‌های خاصی برای دسته‌بندی‌های خاصی از تصاویر فعال می شوند. بنابراین، فشر بینایی مغز روند شناسایی الگو را به صورت سلسله‌مراتبی انجام می‌دهد.


<!--
Experiments in which researchers poked electrodes in specific areas of the visual cortex, specifically the V1 area made researchers realize that certain neurons react to motifs that appear in a very small area in a visual field and similarly with neighbouring neurons and neighbouring areas in the visual field. Additionally, neurons that react to the same visual field, react to different types of edges in an organized manner (*e.g.* vertical or horizontal edges). It is also important to note that there's also the idea that the visual process is essentially a feed forward process. Hence, somehow fast recognition can be done without some recurrent connections.
-->


آزمایشاتی انجام شده است که در آن محققان الکترود‌های نواحی مخصوصی از قشر بینایی را در تحریک کرده‌اند. مخصوصا در ناحیه‌ی 
*V1*
محققان به این نتیجه رسیدند که نورون‌های خاصی در این ناحیه به شکل‌های مخصوصی واکنش نشان می‌دهند. آن هم شکل‌های خاصی که فقط در ناحیه‌ی بسیار کوچکی نسبت به کل فضای دید انسان قرار دارند. و نورون‌های همسایه‌ی آنها دقیقا به اشکل مشابهی واکنش نشان می‌دهند ولی در ناحیه‌ی کوچکی که همسایه‌ی ناحیه‌ی نورون‌های قبلی است. همچنین، نورون‌هایی که به ناحیه‌ی مشابهی در فضای دید واکنش نشان می‌دهند  به اشکال و گوشه‌های متفاوتی واکنش نشان می‌دهند. (مثلا بعضی نورون‌ها به گوشه‌های افقی و بعضی نورون‌ها به گوشه‌های عمودی واکنش نشان می‌دهند) و به نظر می‌رسد که این تفاوت‌ها شکل برنامه‌ریزی شده‌ای دارد و اتفاقی نیست. همچنین مهم است که به این ایده توجه کنیم که بینایی در مغز یک پروسه‌ی یک طرفه
*(feed forward)*
است. بنابراین می‌توان نتیجه گرفت که تشخیص اشیا به صورت خیلی سریع و بدون استفاده از اتصالات بازگشتی
*(recurrent)*
قابل انجام است.